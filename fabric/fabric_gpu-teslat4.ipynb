{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using FABRIC GPUs\n",
    "\n",
    "Your compute nodes can include GPUs. These devices are made available as FABRIC components and can be added to your nodes like any other component.\n",
    "\n",
    "This example notebook will demonstrate how to reserve and use Nvidia GPU devices on FABRIC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Experiment\n",
    "\n",
    "#### Import FABRIC API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_af9cd tr:nth-child(even) {\n",
       "  background: #dbf3ff;\n",
       "  color: #231f20;\n",
       "}\n",
       "#T_af9cd tr:nth-child(odd) {\n",
       "  background: #ffffff;\n",
       "  color: #231f20;\n",
       "}\n",
       "#T_af9cd caption {\n",
       "  text-align: center;\n",
       "  font-size: 150%;\n",
       "}\n",
       "#T_af9cd_row0_col0, #T_af9cd_row0_col1, #T_af9cd_row1_col0, #T_af9cd_row1_col1, #T_af9cd_row2_col0, #T_af9cd_row2_col1, #T_af9cd_row3_col0, #T_af9cd_row3_col1, #T_af9cd_row4_col0, #T_af9cd_row4_col1, #T_af9cd_row5_col0, #T_af9cd_row5_col1, #T_af9cd_row6_col0, #T_af9cd_row6_col1, #T_af9cd_row7_col0, #T_af9cd_row7_col1, #T_af9cd_row8_col0, #T_af9cd_row8_col1, #T_af9cd_row9_col0, #T_af9cd_row9_col1, #T_af9cd_row10_col0, #T_af9cd_row10_col1, #T_af9cd_row11_col0, #T_af9cd_row11_col1, #T_af9cd_row12_col0, #T_af9cd_row12_col1, #T_af9cd_row13_col0, #T_af9cd_row13_col1 {\n",
       "  text-align: left;\n",
       "  border: 1px #231f20 solid !important;\n",
       "  overwrite: False;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_af9cd\">\n",
       "  <caption>FABlib Config</caption>\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_af9cd_row0_col0\" class=\"data row0 col0\" >Credential Manager</td>\n",
       "      <td id=\"T_af9cd_row0_col1\" class=\"data row0 col1\" >cm.fabric-testbed.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_af9cd_row1_col0\" class=\"data row1 col0\" >Orchestrator</td>\n",
       "      <td id=\"T_af9cd_row1_col1\" class=\"data row1 col1\" >orchestrator.fabric-testbed.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_af9cd_row2_col0\" class=\"data row2 col0\" >Token File</td>\n",
       "      <td id=\"T_af9cd_row2_col1\" class=\"data row2 col1\" >/home/fabric/.tokens.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_af9cd_row3_col0\" class=\"data row3 col0\" >Project ID</td>\n",
       "      <td id=\"T_af9cd_row3_col1\" class=\"data row3 col1\" >17f7e488-e1b7-4ea9-b657-e69cdbb27a38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_af9cd_row4_col0\" class=\"data row4 col0\" >Bastion Username</td>\n",
       "      <td id=\"T_af9cd_row4_col1\" class=\"data row4 col1\" >jbrassil_0034513446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_af9cd_row5_col0\" class=\"data row5 col0\" >Bastion Private Key File</td>\n",
       "      <td id=\"T_af9cd_row5_col1\" class=\"data row5 col1\" >/home/fabric/work/fabric_config/id_fabric_bastion_traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_af9cd_row6_col0\" class=\"data row6 col0\" >Bastion Host</td>\n",
       "      <td id=\"T_af9cd_row6_col1\" class=\"data row6 col1\" >bastion.fabric-testbed.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_af9cd_row7_col0\" class=\"data row7 col0\" >Bastion Private Key Passphrase</td>\n",
       "      <td id=\"T_af9cd_row7_col1\" class=\"data row7 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_af9cd_row8_col0\" class=\"data row8 col0\" >Slice Public Key File</td>\n",
       "      <td id=\"T_af9cd_row8_col1\" class=\"data row8 col1\" >/home/fabric/work/fabric_config/slice_key.pub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_af9cd_row9_col0\" class=\"data row9 col0\" >Slice Private Key File</td>\n",
       "      <td id=\"T_af9cd_row9_col1\" class=\"data row9 col1\" >/home/fabric/work/fabric_config/slice_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_af9cd_row10_col0\" class=\"data row10 col0\" >Slice Private Key Passphrase</td>\n",
       "      <td id=\"T_af9cd_row10_col1\" class=\"data row10 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_af9cd_row11_col0\" class=\"data row11 col0\" >Log File</td>\n",
       "      <td id=\"T_af9cd_row11_col1\" class=\"data row11 col1\" >/home/fabric/fablib.log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_af9cd_row12_col0\" class=\"data row12 col0\" >Log Level</td>\n",
       "      <td id=\"T_af9cd_row12_col1\" class=\"data row12 col1\" >INFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_af9cd_row13_col0\" class=\"data row13 col0\" >Version</td>\n",
       "      <td id=\"T_af9cd_row13_col1\" class=\"data row13 col1\" >1.6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f0372b7ff40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "\n",
    "fablib = fablib_manager()\n",
    "                     \n",
    "fablib.show_config();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Node\n",
    "\n",
    "The cells below help you create a slice that contains a single node with an attached GPU. \n",
    "\n",
    "### Select GPU Type and select the FABRIC Site\n",
    "\n",
    "First decide on which GPU type you want to try - this will determine the subset of sites where your VM can be placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_name='tesla_t4_available'\n"
     ]
    }
   ],
   "source": [
    "# pick which GPU type we will use (execute this cell). \n",
    "\n",
    "# choices include\n",
    "# GPU_RTX6000\n",
    "# GPU_TeslaT4\n",
    "# GPU_A30\n",
    "# GPU_A40\n",
    "GPU_CHOICE = 'GPU_TeslaT4' \n",
    "\n",
    "# don't edit - convert from GPU type to a resource column name\n",
    "# to use in filter lambda function below\n",
    "choice_to_column = {\n",
    "    \"GPU_RTX6000\": \"rtx6000_available\",\n",
    "    \"GPU_TeslaT4\": \"tesla_t4_available\",\n",
    "    \"GPU_A30\": \"a30_available\",\n",
    "    \"GPU_A40\": \"a40_available\"\n",
    "}\n",
    "\n",
    "column_name = choice_to_column.get(GPU_CHOICE, \"Unknown\")\n",
    "print(f'{column_name=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give the slice and the node in it meaningful names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will create slice \"TeslaT4-perf\" with node \"gpu-node\"\n"
     ]
    }
   ],
   "source": [
    "# name the slice and the node \n",
    "slice_name=f'TeslaT4-perf'\n",
    "node_name='gpu-node'\n",
    "\n",
    "print(f'Will create slice \"{slice_name}\" with node \"{node_name}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a lambda filter to figure out which site the node will go to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to create slice \"TeslaT4-perf\" with node gpu-node in site GPN\n"
     ]
    }
   ],
   "source": [
    "# find a site with at least one available GPU of the selected type\n",
    "site_override = None\n",
    "\n",
    "if site_override:\n",
    "    site = site_override\n",
    "else:\n",
    "    site = fablib.get_random_site(filter_function=lambda x: x[column_name] > 0)\n",
    "print(f'Preparing to create slice \"{slice_name}\" with node {node_name} in site {site}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the desired slice with a GPU component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Submit request error: return_status Status.FAILURE, slice_reservations: (500)\nReason: INTERNAL SERVER ERROR\nHTTP response headers: HTTPHeaderDict({'Server': 'nginx/1.21.6', 'Date': 'Wed, 10 Apr 2024 09:43:00 GMT', 'Content-Type': 'text/html; charset=utf-8', 'Content-Length': '207', 'Connection': 'keep-alive', 'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Headers': 'DNT, User-Agent, X-Requested-With, If-Modified-Since, Cache-Control, Content-Type, Range, Authorization', 'Access-Control-Allow-Methods': 'GET, POST, PUT, PATCH, DELETE, OPTIONS', 'Access-Control-Allow-Origin': '*', 'Access-Control-Expose-Headers': 'Content-Length, Content-Range, X-Error', 'X-Error': 'Slice TeslaT4-perf already exists'})\nHTTP response body: b'{\\n    \"errors\": [\\n        {\\n            \"details\": \"Slice TeslaT4-perf already exists\",\\n            \"message\": \"Internal Server Error\"\\n        }\\n    ],\\n    \"size\": 1,\\n    \"status\": 500,\\n    \"type\": \"error\"\\n}'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m node\u001b[38;5;241m.\u001b[39madd_component(model\u001b[38;5;241m=\u001b[39mGPU_CHOICE, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#Submit Slice Request\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;43mslice\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m;\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fabrictestbed_extensions/fablib/slice.py:2008\u001b[0m, in \u001b[0;36mSlice.submit\u001b[0;34m(self, wait, wait_timeout, wait_interval, progress, wait_jupyter, post_boot_config, wait_ssh, extra_ssh_keys)\u001b[0m\n\u001b[1;32m   2004\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2005\u001b[0m         logging\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m   2006\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubmit request error: return_status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_status\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, slice_reservations: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mslice_reservations\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2007\u001b[0m         )\n\u001b[0;32m-> 2008\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m   2009\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubmit request error: return_status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_status\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, slice_reservations: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mslice_reservations\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2010\u001b[0m         )\n\u001b[1;32m   2012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_status \u001b[38;5;241m!=\u001b[39m Status\u001b[38;5;241m.\u001b[39mOK:\n\u001b[1;32m   2013\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m   2014\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to submit slice: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2015\u001b[0m             return_status, slice_reservations\n\u001b[1;32m   2016\u001b[0m         )\n\u001b[1;32m   2017\u001b[0m     )\n",
      "\u001b[0;31mException\u001b[0m: Submit request error: return_status Status.FAILURE, slice_reservations: (500)\nReason: INTERNAL SERVER ERROR\nHTTP response headers: HTTPHeaderDict({'Server': 'nginx/1.21.6', 'Date': 'Wed, 10 Apr 2024 09:43:00 GMT', 'Content-Type': 'text/html; charset=utf-8', 'Content-Length': '207', 'Connection': 'keep-alive', 'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Headers': 'DNT, User-Agent, X-Requested-With, If-Modified-Since, Cache-Control, Content-Type, Range, Authorization', 'Access-Control-Allow-Methods': 'GET, POST, PUT, PATCH, DELETE, OPTIONS', 'Access-Control-Allow-Origin': '*', 'Access-Control-Expose-Headers': 'Content-Length, Content-Range, X-Error', 'X-Error': 'Slice TeslaT4-perf already exists'})\nHTTP response body: b'{\\n    \"errors\": [\\n        {\\n            \"details\": \"Slice TeslaT4-perf already exists\",\\n            \"message\": \"Internal Server Error\"\\n        }\\n    ],\\n    \"size\": 1,\\n    \"status\": 500,\\n    \"type\": \"error\"\\n}'\n"
     ]
    }
   ],
   "source": [
    "# Create Slice. Note that by default submit() call will poll for 360 seconds every 10-20 seconds\n",
    "# waiting for slice to come up. Normal expected time is around 2 minutes. \n",
    "slice = fablib.new_slice(name=slice_name)\n",
    "\n",
    "# Add node with a 100G drive and a couple of CPU cores (default)\n",
    "node = slice.add_node(name=node_name, site=site, disk=100, image='default_ubuntu_22')\n",
    "node.add_component(model=GPU_CHOICE, name='gpu1')\n",
    "\n",
    "#Submit Slice Request\n",
    "slice.submit();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Slice\n",
    "\n",
    "Retrieve the node information and save the management IP addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)\n",
    "slice.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Node\n",
    "\n",
    "Retrieve the node information and save the management IP address.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = slice.get_node(node_name) \n",
    "node.show()\n",
    "\n",
    "gpu = node.get_component('gpu1')\n",
    "gpu.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU PCI Device\n",
    "\n",
    "Run the command <code>lspci</code> to see your GPU PCI device(s). This is the raw GPU PCI device that is not yet configured for use.  You can use the GPUs as you would any GPUs.\n",
    "\n",
    "View node's GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"sudo apt-get install -y pciutils && lspci | grep 'NVIDIA\\|3D controller'\"\n",
    "\n",
    "stdout, stderr = node.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Nvidia Drivers\n",
    "\n",
    "Now, let's run the following commands to install the latest NVidia driver and the CUDA libraries and compiler. This step can take up to 20 minutes.\n",
    "\n",
    "NOTE: for instructional purposes the following cell sends all command output back to the notebook. You can also send it to log files to keep the notebook output clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distro='ubuntu2204'\n",
    "version='12.2'\n",
    "architecture='x86_64'\n",
    "\n",
    "# install prerequisites\n",
    "commands = [\n",
    "    'sudo apt-get -q update',\n",
    "    'sudo apt-get -q install -y linux-headers-$(uname -r) gcc',\n",
    "]\n",
    "\n",
    "print(\"Installing Prerequisites...\")\n",
    "for command in commands:\n",
    "    print(f\"++++ {command}\")\n",
    "    stdout, stderr = node.execute(command)\n",
    "\n",
    "print(f\"Installing CUDA {version}\")\n",
    "commands = [\n",
    "    f'wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb',\n",
    "    f'sudo dpkg -i cuda-keyring_1.1-1_all.deb',\n",
    "    'sudo apt-get -q update',\n",
    "    'sudo apt-get -q install -y cuda'\n",
    "]\n",
    "print(\"Installing CUDA...\")\n",
    "for command in commands:\n",
    "    print(f\"++++ {command}\")\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print(\"Done installing CUDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And once CUDA is installed, reboot the machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reboot = 'sudo reboot'\n",
    "\n",
    "print(reboot)\n",
    "node.execute(reboot)\n",
    "\n",
    "slice.wait_ssh(timeout=360,interval=10,progress=True)\n",
    "\n",
    "print(\"Now testing SSH abilites to reconnect...\",end=\"\")\n",
    "slice.update()\n",
    "slice.test_ssh()\n",
    "print(\"Reconnected!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the GPU and CUDA Installation\n",
    "\n",
    "First, verify that the Nvidia drivers recognize the GPU by running `nvidia-smi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stdout, stderr = node.execute(\"nvidia-smi\")\n",
    "\n",
    "print(f\"stdout: {stdout}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's upload the following \"Hello World\" CUDA program file to the node.\n",
    "\n",
    "`hello-world.cu`\n",
    "\n",
    "*Source: https://computer-graphics.se/multicore/pdf/hello-world.cu*\n",
    "\n",
    "*Author: Ingemar Ragnemalm*\n",
    "\n",
    ">This file is from *\"The real \"Hello World!\" for CUDA, OpenCL and GLSL!\"* (https://computer-graphics.se/hello-world-for-cuda.html), written by Ingemar Ragnemalm, programmer and CUDA teacher. The only changes (if you download the original file from the website) are to additionally `#include <unistd.h>`, as `sleep()` is now a fuction defined in the `unistd.h` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.upload_file('./hello-world.cu', 'hello-world.cu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.upload_file('./lightning_mnist_example.ipynb', 'lightning_mnist_example.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.upload_file('./lightning_mnist_example.py', 'lightning_mnist_example.py')\n",
    "node.upload_file('./installer.sh', './installer.sh')\n",
    "#node.upload_file('./lightning_mnist_example-install1.py', 'lightning_mnist_example-install1.py')\n",
    "#node.upload_file('./lightning_mnist_example-install2.py', 'lightning_mnist_example-install2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node.download_file('./lightning_mnist_example.py', 'lightning_mnist_example.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compile the `.cu` file using `nvcc`, the CUDA compiler tool installed with CUDA. In this example, we create an executable called `hello_world`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = node.execute(f\"/usr/local/cuda-{12.4}/bin/nvcc -o hello_world hello-world.cu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the executable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stdout, stderr = node.execute(\"./hello_world\")\n",
    "\n",
    "print(f\"stdout: {stdout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = node.execute(\"bash ./installer.sh\")\n",
    "stdout, stderr = node.execute(\"python3 ./lightning_mnist_example.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see `Hello World!`, the CUDA program ran successfully. `World!` was computed on the GPU from an array of offsets being summed with the string `Hello `, and the resut was printed to stdout.\n",
    "\n",
    "### Congratulations! You have now successfully run a program on a FABRIC GPU!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup Your Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fablib.delete_slice(slice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
